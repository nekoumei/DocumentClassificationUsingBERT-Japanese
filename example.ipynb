{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>【DVDエンター！】誘拐犯に育てられた女が目にした真実は、孤独か幸福か2005年11月から翌...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>藤原竜也、中学生とともにロケット打ち上げに成功「アンテナを張りながら生活をしていけばいい」2...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>『戦火の馬』ロイヤル・プレミアにウィリアム王子＆キャサリン妃が出席3月2日より全国ロードショ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>香里奈、女子高生100人のガチンコ質問に回答「ラーメンも食べる」女優の香里奈が18日、都内で...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>ユージの前に立ちはだかったJOY「僕はAKBの高橋みなみを守る」5日、東京・千代田区の内幸町...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Label\n",
       "0  【DVDエンター！】誘拐犯に育てられた女が目にした真実は、孤独か幸福か2005年11月から翌...      4\n",
       "1  藤原竜也、中学生とともにロケット打ち上げに成功「アンテナを張りながら生活をしていけばいい」2...      4\n",
       "2  『戦火の馬』ロイヤル・プレミアにウィリアム王子＆キャサリン妃が出席3月2日より全国ロードショ...      4\n",
       "3  香里奈、女子高生100人のガチンコ質問に回答「ラーメンも食べる」女優の香里奈が18日、都内で...      4\n",
       "4  ユージの前に立ちはだかったJOY「僕はAKBの高橋みなみを守る」5日、東京・千代田区の内幸町...      4"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "import random\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import DocumentClassifierUsingBertJapanese as clf\n",
    "\n",
    "df = pd.read_csv('path/to/data/news.csv.gz')\n",
    "le = LabelEncoder()\n",
    "df['label'] = le.fit_transform(df.label.values)\n",
    "df = df[['text', 'label']]\n",
    "df.columns = ['Text', 'Label']\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, stratify=df.Label)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1215 23:49:39.759165 139626452043584 tokenization_utils.py:398] loading file https://s3.amazonaws.com/models.huggingface.co/bert/cl-tohoku/bert-base-japanese-whole-word-masking-vocab.txt from cache at /home/nekoumei/.cache/torch/transformers/ae4d597c0697c617ab6c6c913effc265b7e606830a3b373dfcaeca1794ab9229.5fac9da4d8565963664ed9744688dc7008ff5ec4045f604e9515896f9fe46d9c\n",
      "I1215 23:49:40.888530 139626452043584 configuration_utils.py:160] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/cl-tohoku/bert-base-japanese-whole-word-masking-config.json from cache at /home/nekoumei/.cache/torch/transformers/3c7c1cf64fda50b267a0e88bd23a88a7eaae4e8205f6ee4ceb472ef9e3274f29.3d9f46e22d98b122f65c2c48727301903ca4a5381c3e967e2ba93f0ae64dee75\n",
      "I1215 23:49:40.890443 139626452043584 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 9,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n",
      "I1215 23:49:41.761940 139626452043584 modeling_utils.py:401] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/cl-tohoku/bert-base-japanese-whole-word-masking-pytorch_model.bin from cache at /home/nekoumei/.cache/torch/transformers/a2f827453709c7a74b48468cfea4ca3c7ebc260308a4cd52d5231dd02b73e315.6225a45d8bbedb200842a8cef5bc97d0631dad427835b9e916dfeb1c3b2a91e8\n",
      "I1215 23:49:44.412322 139626452043584 modeling_utils.py:473] Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n",
      "I1215 23:49:44.412951 139626452043584 modeling_utils.py:476] Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "[I 191215 23:49:44 DocumentClassifierUsingBertJapanese:164] [Start]Create DataSets from DataFrames\n",
      "[I 191215 23:49:59 DocumentClassifierUsingBertJapanese:167] [Finished]Create DataSets from DataFrames\n",
      "[I 191215 23:49:59 DocumentClassifierUsingBertJapanese:171] [Start]Create DataLoaders\n",
      "[I 191215 23:49:59 DocumentClassifierUsingBertJapanese:174] [Finished]Create DataLoaders\n",
      "[I 191215 23:49:59 DocumentClassifierUsingBertJapanese:219] 使用デバイス：cuda:0\n",
      "[I 191215 23:49:59 DocumentClassifierUsingBertJapanese:220] -----start-------\n",
      "[I 191215 23:52:34 DocumentClassifierUsingBertJapanese:305] Epoch 1/100 | train |  Loss: 1.0900 Acc: 0.6884 F1-Score: 0.660202\n",
      "[I 191215 23:53:06 DocumentClassifierUsingBertJapanese:305] Epoch 1/100 |  val  |  Loss: 0.4554 Acc: 0.8738 F1-Score: 0.863950\n",
      "[I 191215 23:53:06 DocumentClassifierUsingBertJapanese:65] Validation loss decreased (inf --> 0.455443).  Saving model ...\n",
      "[I 191215 23:55:40 DocumentClassifierUsingBertJapanese:305] Epoch 2/100 | train |  Loss: 0.3615 Acc: 0.9004 F1-Score: 0.893412\n",
      "[I 191215 23:56:13 DocumentClassifierUsingBertJapanese:305] Epoch 2/100 |  val  |  Loss: 0.2671 Acc: 0.9220 F1-Score: 0.915514\n",
      "[I 191215 23:56:13 DocumentClassifierUsingBertJapanese:65] Validation loss decreased (0.455443 --> 0.267138).  Saving model ...\n",
      "[I 191215 23:58:47 DocumentClassifierUsingBertJapanese:305] Epoch 3/100 | train |  Loss: 0.2227 Acc: 0.9398 F1-Score: 0.934808\n",
      "[I 191215 23:59:19 DocumentClassifierUsingBertJapanese:305] Epoch 3/100 |  val  |  Loss: 0.2419 Acc: 0.9308 F1-Score: 0.923238\n",
      "[I 191215 23:59:19 DocumentClassifierUsingBertJapanese:65] Validation loss decreased (0.267138 --> 0.241861).  Saving model ...\n",
      "[I 191216 00:01:54 DocumentClassifierUsingBertJapanese:305] Epoch 4/100 | train |  Loss: 0.1557 Acc: 0.9598 F1-Score: 0.956070\n",
      "[I 191216 00:02:26 DocumentClassifierUsingBertJapanese:305] Epoch 4/100 |  val  |  Loss: 0.1937 Acc: 0.9417 F1-Score: 0.937097\n",
      "[I 191216 00:02:26 DocumentClassifierUsingBertJapanese:65] Validation loss decreased (0.241861 --> 0.193738).  Saving model ...\n",
      "[I 191216 00:05:00 DocumentClassifierUsingBertJapanese:305] Epoch 5/100 | train |  Loss: 0.1164 Acc: 0.9701 F1-Score: 0.968034\n",
      "[I 191216 00:05:32 DocumentClassifierUsingBertJapanese:305] Epoch 5/100 |  val  |  Loss: 0.1890 Acc: 0.9417 F1-Score: 0.936151\n",
      "[I 191216 00:05:32 DocumentClassifierUsingBertJapanese:65] Validation loss decreased (0.193738 --> 0.188992).  Saving model ...\n",
      "[I 191216 00:08:07 DocumentClassifierUsingBertJapanese:305] Epoch 6/100 | train |  Loss: 0.0889 Acc: 0.9761 F1-Score: 0.974574\n",
      "[I 191216 00:08:39 DocumentClassifierUsingBertJapanese:305] Epoch 6/100 |  val  |  Loss: 0.1760 Acc: 0.9478 F1-Score: 0.943974\n",
      "[I 191216 00:08:39 DocumentClassifierUsingBertJapanese:65] Validation loss decreased (0.188992 --> 0.176042).  Saving model ...\n",
      "[I 191216 00:11:13 DocumentClassifierUsingBertJapanese:305] Epoch 7/100 | train |  Loss: 0.0724 Acc: 0.9807 F1-Score: 0.978966\n",
      "[I 191216 00:11:45 DocumentClassifierUsingBertJapanese:305] Epoch 7/100 |  val  |  Loss: 0.1890 Acc: 0.9484 F1-Score: 0.944529\n",
      "[I 191216 00:11:45 DocumentClassifierUsingBertJapanese:54] EarlyStopping counter: 1 out of 10\n",
      "[I 191216 00:14:19 DocumentClassifierUsingBertJapanese:305] Epoch 8/100 | train |  Loss: 0.0470 Acc: 0.9881 F1-Score: 0.987141\n",
      "[I 191216 00:14:51 DocumentClassifierUsingBertJapanese:305] Epoch 8/100 |  val  |  Loss: 0.1775 Acc: 0.9539 F1-Score: 0.949814\n",
      "[I 191216 00:14:51 DocumentClassifierUsingBertJapanese:54] EarlyStopping counter: 2 out of 10\n",
      "[I 191216 00:17:25 DocumentClassifierUsingBertJapanese:305] Epoch 9/100 | train |  Loss: 0.0425 Acc: 0.9883 F1-Score: 0.987736\n",
      "[I 191216 00:17:57 DocumentClassifierUsingBertJapanese:305] Epoch 9/100 |  val  |  Loss: 0.1853 Acc: 0.9471 F1-Score: 0.941917\n",
      "[I 191216 00:17:57 DocumentClassifierUsingBertJapanese:54] EarlyStopping counter: 3 out of 10\n",
      "[I 191216 00:20:31 DocumentClassifierUsingBertJapanese:305] Epoch 10/100 | train |  Loss: 0.0323 Acc: 0.9925 F1-Score: 0.991625\n",
      "[I 191216 00:21:03 DocumentClassifierUsingBertJapanese:305] Epoch 10/100 |  val  |  Loss: 0.1757 Acc: 0.9512 F1-Score: 0.946010\n",
      "[I 191216 00:21:03 DocumentClassifierUsingBertJapanese:65] Validation loss decreased (0.176042 --> 0.175742).  Saving model ...\n",
      "[I 191216 00:23:37 DocumentClassifierUsingBertJapanese:305] Epoch 11/100 | train |  Loss: 0.0277 Acc: 0.9930 F1-Score: 0.992692\n",
      "[I 191216 00:24:09 DocumentClassifierUsingBertJapanese:305] Epoch 11/100 |  val  |  Loss: 0.1999 Acc: 0.9498 F1-Score: 0.944804\n",
      "[I 191216 00:24:09 DocumentClassifierUsingBertJapanese:54] EarlyStopping counter: 1 out of 10\n",
      "[I 191216 00:26:43 DocumentClassifierUsingBertJapanese:305] Epoch 12/100 | train |  Loss: 0.0229 Acc: 0.9949 F1-Score: 0.994701\n",
      "[I 191216 00:27:15 DocumentClassifierUsingBertJapanese:305] Epoch 12/100 |  val  |  Loss: 0.1864 Acc: 0.9552 F1-Score: 0.950752\n",
      "[I 191216 00:27:15 DocumentClassifierUsingBertJapanese:54] EarlyStopping counter: 2 out of 10\n",
      "[I 191216 00:29:49 DocumentClassifierUsingBertJapanese:305] Epoch 13/100 | train |  Loss: 0.0201 Acc: 0.9956 F1-Score: 0.995573\n",
      "[I 191216 00:30:21 DocumentClassifierUsingBertJapanese:305] Epoch 13/100 |  val  |  Loss: 0.1981 Acc: 0.9545 F1-Score: 0.948678\n",
      "[I 191216 00:30:21 DocumentClassifierUsingBertJapanese:54] EarlyStopping counter: 3 out of 10\n",
      "[I 191216 00:32:55 DocumentClassifierUsingBertJapanese:305] Epoch 14/100 | train |  Loss: 0.0189 Acc: 0.9944 F1-Score: 0.993899\n",
      "[I 191216 00:33:27 DocumentClassifierUsingBertJapanese:305] Epoch 14/100 |  val  |  Loss: 0.1992 Acc: 0.9498 F1-Score: 0.945150\n",
      "[I 191216 00:33:27 DocumentClassifierUsingBertJapanese:54] EarlyStopping counter: 4 out of 10\n",
      "[I 191216 00:36:01 DocumentClassifierUsingBertJapanese:305] Epoch 15/100 | train |  Loss: 0.0244 Acc: 0.9930 F1-Score: 0.992623\n",
      "[I 191216 00:36:33 DocumentClassifierUsingBertJapanese:305] Epoch 15/100 |  val  |  Loss: 0.2177 Acc: 0.9505 F1-Score: 0.945873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 191216 00:36:33 DocumentClassifierUsingBertJapanese:54] EarlyStopping counter: 5 out of 10\n",
      "[I 191216 00:39:06 DocumentClassifierUsingBertJapanese:305] Epoch 16/100 | train |  Loss: 0.0176 Acc: 0.9956 F1-Score: 0.995412\n",
      "[I 191216 00:39:38 DocumentClassifierUsingBertJapanese:305] Epoch 16/100 |  val  |  Loss: 0.1956 Acc: 0.9559 F1-Score: 0.951474\n",
      "[I 191216 00:39:38 DocumentClassifierUsingBertJapanese:54] EarlyStopping counter: 6 out of 10\n",
      "[I 191216 00:42:12 DocumentClassifierUsingBertJapanese:305] Epoch 17/100 | train |  Loss: 0.0163 Acc: 0.9954 F1-Score: 0.995031\n",
      "[I 191216 00:42:44 DocumentClassifierUsingBertJapanese:305] Epoch 17/100 |  val  |  Loss: 0.1950 Acc: 0.9579 F1-Score: 0.953574\n",
      "[I 191216 00:42:44 DocumentClassifierUsingBertJapanese:54] EarlyStopping counter: 7 out of 10\n",
      "[I 191216 00:45:18 DocumentClassifierUsingBertJapanese:305] Epoch 18/100 | train |  Loss: 0.0154 Acc: 0.9963 F1-Score: 0.996100\n",
      "[I 191216 00:45:50 DocumentClassifierUsingBertJapanese:305] Epoch 18/100 |  val  |  Loss: 0.2344 Acc: 0.9525 F1-Score: 0.948543\n",
      "[I 191216 00:45:50 DocumentClassifierUsingBertJapanese:54] EarlyStopping counter: 8 out of 10\n",
      "[I 191216 00:48:24 DocumentClassifierUsingBertJapanese:305] Epoch 19/100 | train |  Loss: 0.0209 Acc: 0.9934 F1-Score: 0.993054\n",
      "[I 191216 00:48:56 DocumentClassifierUsingBertJapanese:305] Epoch 19/100 |  val  |  Loss: 0.1970 Acc: 0.9566 F1-Score: 0.952101\n",
      "[I 191216 00:48:56 DocumentClassifierUsingBertJapanese:54] EarlyStopping counter: 9 out of 10\n",
      "[I 191216 00:51:29 DocumentClassifierUsingBertJapanese:305] Epoch 20/100 | train |  Loss: 0.0139 Acc: 0.9968 F1-Score: 0.996637\n",
      "[I 191216 00:52:01 DocumentClassifierUsingBertJapanese:305] Epoch 20/100 |  val  |  Loss: 0.1982 Acc: 0.9566 F1-Score: 0.952272\n",
      "[I 191216 00:52:01 DocumentClassifierUsingBertJapanese:54] EarlyStopping counter: 10 out of 10\n",
      "[I 191216 00:52:01 DocumentClassifierUsingBertJapanese:312] Early stopping\n",
      "[I 191216 00:52:02 DocumentClassifierUsingBertJapanese:322] [Start]Create DataSet, DataLoader from DataFrame\n",
      "[I 191216 00:52:04 DocumentClassifierUsingBertJapanese:325] [Finished]Create DataSet, DataLoader from DataFrame\n",
      "[I 191216 00:52:04 DocumentClassifierUsingBertJapanese:328] 使用デバイス：cuda:0\n",
      "[I 191216 00:52:04 DocumentClassifierUsingBertJapanese:329] -----start-------\n",
      "100%|██████████| 47/47 [00:32<00:00,  1.46it/s]\n",
      "[I 191216 00:52:37 DocumentClassifierUsingBertJapanese:339] -----finished-------\n"
     ]
    }
   ],
   "source": [
    "model = clf.DocumentClassifier(num_labels=9, num_epochs=100)\n",
    "model.fit(train_df, val_df, early_stopping_rounds=10)\n",
    "y_proba = model.predict(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.2045135e-03, 3.2994938e-06, 9.7928678e-05, ..., 4.2110952e-04,\n",
       "        2.1126025e-04, 4.9316594e-05],\n",
       "       [2.6260054e-04, 9.9660146e-01, 1.8752258e-03, ..., 3.6985122e-04,\n",
       "        3.1780226e-05, 5.2989175e-04],\n",
       "       [1.5996837e-04, 2.2008653e-05, 4.1546031e-05, ..., 1.7764495e-04,\n",
       "        4.5199366e-04, 9.9877280e-01],\n",
       "       ...,\n",
       "       [9.9923754e-01, 4.7426103e-05, 1.1255769e-04, ..., 2.0333318e-04,\n",
       "        5.3641583e-05, 1.5663210e-04],\n",
       "       [9.9885798e-01, 7.8204626e-05, 9.8405311e-05, ..., 1.1104005e-04,\n",
       "        4.2987678e-05, 5.9029361e-04],\n",
       "       [2.1035015e-03, 1.3707391e-03, 1.3844197e-04, ..., 9.5234132e-01,\n",
       "        1.0645230e-03, 3.6875196e-04]], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
